# Arxiv Analysis: AutoLink: Autonomous Schema Exploration and Expansion for Scalable Schema Linking in Text-to-SQL at Scale

**ID:** 2511.17190
**Date:** 2024-11-26
**Link:** https://arxiv.org/abs/2511.17190

## Executive Summary
The paper introduces AutoLink, an autonomous agent framework designed to tackle the schema linking problem in large-scale Text-to-SQL systems. Instead of supplying an entire database schema to a Large Language Model (LLM), which is often impractical due to context window limitations and noise, AutoLink employs an agent that iteratively explores and expands a relevant subset of the schema. The agent interacts with two environments: a direct database environment for executing SQL queries and a vector store for semantic search of schema components. Through a series of actions like exploration, retrieval, verification, and expansion, the agent dynamically builds the necessary schema context to answer a natural language question. This approach achieves state-of-the-art recall in schema linking, demonstrates superior scalability, and maintains high token efficiency, making it highly suitable for industrial applications.

## Idea Brainstorming
*What concepts are potentially useful for THIS project?*
- **Concept 1: Natural Language Interface for CryptoSentinel Data.** We can create a new `DataQueryAgent` based on the AutoLink principles. This agent would allow users or other agents to query the project's `khala-agentmemory` (SurrealDB) using natural language. For example, an analyst could ask, "What was the `RiskAnalyst`'s average capital allocation for trades over the past 7 days?" without needing to know the exact table and column names.
- **Concept 2: Dynamic and Adaptive Data Gathering for Agents.** Instead of relying on pre-defined, static tools for data retrieval, agents like `MarketAnalyst` could use the AutoLink mechanism to dynamically find and query the most relevant data for their current task. If a new type of data is added to the database, the agent could discover and use it without needing its tools to be explicitly updated. This would make the entire system more robust and adaptable to schema evolution.
- **Concept 3: Enhanced Agent-to-Agent Communication.** When one agent needs data from another, it often has to know the specific format or function to call. With an AutoLink-inspired approach, an agent could simply ask another agent a question in natural language (e.g., `Trader` asking `MarketAnalyst`: "What are the top 3 most volatile assets right now?"). The receiving agent could then use its own internal AutoLink process to query its knowledge base and provide the answer.

## Gap Analysis
*Compare paper concepts vs. `current_codebase`. What do we already have? What is missing?*

| Feature/Concept | Current State (Codebase) | Missing / Needed |
| :--- | :--- | :--- |
| **Autonomous Agent Framework** | The project uses the Agno framework, which supports multi-agent systems. Agents have defined roles and tools. | The specific iterative, self-correcting reasoning loop described in AutoLink is not explicitly implemented. This would require new prompting strategies. |
| **Schema Vector Store** | The `khala-agentmemory` component uses a vector store (SurrealDB), but it is for storing and retrieving agent memories and experiences, not database schema definitions. | A dedicated process to extract, embed, and index the database schema into a vector store is needed. This includes tables, columns, types, and descriptions. |
| **Agent Action Space** | Agents have toolkits (`backend/tools/`) with various capabilities (e.g., web search, file operations). | The specific, fine-grained actions from the paper are missing: `@explore_schema` (direct SQL execution for metadata), `@retrieve_schema` (semantic search for schema elements), `@verify_schema` (testing a hypothesis), and `@add_schema` (updating the context). |
| **SQL Generation & Execution** | There is no generic Text-to-SQL generation capability. Data access is typically done through hardcoded queries or ORM-like methods within tools. | A complete Text-to-SQL generation module, including self-consistency, syntactic correction, and majority voting, would need to be built. |

## Implementation Plan
*Granular, step-by-step task list to port the ideas to our code.*

- [ ] **Phase 1: Environment Setup**
    - [ ] Develop a script (`scripts/index_schema.py`) to connect to the project's SurrealDB, introspect its schema (tables, fields, types), and create structured documents for each column.
    - [ ] Embed these schema documents using a sentence transformer model and index them into a dedicated vector store within `khala-agentmemory`.
- [ ] **Phase 2: Agent & Tool Development**
    - [ ] Create a new toolkit, `DatabaseToolkit`, in `backend/tools/database_toolkit.py`.
    - [ ] Implement the `explore_schema` tool, which allows an agent to execute a read-only SQL query against the database.
    - [ ] Implement the `retrieve_schema` tool, which takes a natural language query, embeds it, and searches the schema vector store to find relevant tables/columns.
    - [ ] Implement the `verify_schema` tool, which attempts to generate and execute a full SQL query to test for schema sufficiency.
- [ ] **Phase 3: Agent Integration**
    - [ ] Create a new agent, `DataQueryAgent`, in `backend/agents/DataQueryAgent/`.
    - [ ] Develop a new prompt template (`backend/prompts/templates/data_query_agent.txt`) that instructs the agent to follow the AutoLink methodology: start with an initial retrieval, then iteratively use the tools to build a schema context until it can answer the user's question.
    - [ ] Integrate the `DataQueryAgent` into the agent factory in `backend/factory.py`.
- [ ] **Phase 4: SQL Generation Module**
    - [ ] Implement a SQL generation module that takes the final linked schema and the user's question to produce a SQL query.
    - [ ] Add features for self-consistency (sampling multiple candidates), iterative correction (using feedback from the DB), and majority voting based on execution results.
