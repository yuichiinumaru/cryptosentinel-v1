# Arxiv Analysis: SkillWrapper: Generative Predicate Invention for Skill Abstraction

**ID:** 2511.18203
**Date:** 2024-10-25
**Link:** https://arxiv.org/abs/2511.18203

## Executive Summary
The paper introduces "SkillWrapper," a method that leverages foundation models to automatically learn symbolic representations (preconditions and effects) of an agent's black-box skills. It achieves this through "generative predicate invention," where the model creates new, human-interpretable predicates (e.g., `is_on_cutting_board`) to explain why a skill succeeded or failed by observing contrastive outcomes. The core contribution is a formal framework providing theoretical guarantees on the soundness and probabilistic completeness of the learned models, making them reliable for long-horizon planning. This approach enables agents to build abstract, plannable knowledge from raw sensory input (like images) with minimal human supervision.

## Idea Brainstorming
*What concepts are potentially useful for THIS project?*
- **Generative Predicate Invention for Market States:** Instead of inventing predicates for robotic actions, we can invent them for complex market conditions. When a trading strategy underperforms, the system could invent a new predicate like `is_high_volatility_squeeze` or `is_btc_dominance_falling` to explain the failure. This creates a rich, emergent vocabulary for the `MarketAnalyst` and `DeepTraderManager` agents, moving beyond static, predefined concepts.

- **Contrastive Failure Analysis for Toolkits:** The paper's method is triggered when a model fails to distinguish success from failure. We can apply this to our `Toolkits`. When a tool call fails (e.g., a DEX swap fails due to high slippage), the `CognitiveCoordinator` could compare the failed state with a previous successful state for the same tool. It would then ask an LLM to propose a new predicate/condition to prevent future failures, such as inventing a `has_sufficient_slippage_allowance` predicate that gets added to the preconditions of the swap tool's symbolic operator.

- **Active Data Collection for Strategy Backtesting:** SkillWrapper actively proposes skill sequences to gather the most informative data. We can adapt this for strategy optimization. An "ActiveExplorer" agent could propose sequences of market conditions (e.g., "high inflation -> interest rate hike -> sideways market") to test the robustness of our trading strategies, rather than only backtesting linearly on historical data. This helps proactively find and patch blind spots.

- **Symbolic Operator Learning for Trading Strategies:** The paper learns PDDL-style operators. We can model our trading strategies as formal symbolic operators. For example, a "Mean Reversion" strategy could be an operator with preconditions like `is_oversold(asset)` and `is_low_volume(market)`, and effects like `position_opened` and `expected_profit_updated`. Learning these operators automatically from backtesting results would make the system's strategic layer transparent, verifiable, and easier for a `PlannerAgent` to reason about.

## Gap Analysis
*Compare paper concepts vs. `current_codebase`. What do we already have? What is missing?*

| Feature/Concept | Current State (Codebase) | Missing / Needed |
| :--- | :--- | :--- |
| **Predicate Invention** | Static, predefined concepts are encoded in `instructions.md` and prompts. No mechanism exists for creating a new symbolic vocabulary at runtime. | A `PredicateInventionToolkit` that can be triggered by agents. This service would use an LLM to propose new predicates based on contrastive state examples and store them in `KhalaMemory`. |
| **Active Data Collection** | Data collection is passive (market feeds). Strategy backtesting is likely sequential over historical data without intelligent sampling. | An `ActiveExplorer` agent that can propose hypothetical scenarios or intelligently sample historical data to find the most informative transitions (successes/failures) for model learning. |
| **Contrastive State Analysis** | No explicit mechanism. Agents may reason about failures in their thought process, but it's not a structured, automated process based on comparing distinct low-level states. | A `StateComparator` tool that can take two states (e.g., from `KhalaMemory`) and highlight symbolic differences. This tool would provide the necessary input for the `PredicateInventionToolkit`. |
| **Symbolic Operator Learning** | Strategies are likely encoded as Python logic or within agent prompts. They are not formal, verifiable symbolic models that can be easily composed or analyzed. | A `StrategyOperatorLearner` agent. It would take clusters of trade executions and abstract them into a PDDL-like operator with learned preconditions and effects, using the full set of available predicates. |
| **Formal Guarantees** | The system relies on empirical testing and the implicit reasoning of LLMs, with no formal guarantees on the soundness or completeness of its strategic models. | While provable guarantees are difficult, we can move closer with a `Verification` step. A `VerifierAgent` could run simulated tests on newly learned operators/predicates to check for inconsistencies before they are fully deployed. |

## Implementation Plan
*Granular, step-by-step task list to port the ideas to our code, designed to integrate with the planned ARTEMIS architecture.*

- [ ] **Task 1: Design `PredicateInventionToolkit`.**
    - Define the Toolkit's interface: `invent_predicate(successful_state, failed_state) -> Predicate`.
    - The tool would take two state representations (e.g., JSON summaries of market data or just timestamps).
    - It will use a powerful LLM with a specialized prompt (inspired by Appendix H.7 of the paper) to generate a predicate name, parameters, and semantic description.
- [ ] **Task 2: Integrate Predicate Invention into `CognitiveCoordinator`.**
    - Update the planned `CognitiveCoordinator` agent to catch tool failures or strategy underperformance events.
    - Upon failure, it should retrieve the current state and a relevant past successful state from `KhalaMemory`.
    - It will then call the `PredicateInventionToolkit` to generate a new predicate that explains the difference and can be used to prevent future failures.
- [ ] **Task 3: Enhance `KhalaMemoryToolkit` for Dynamic Predicates.**
    - Add functions to `KhalaMemoryToolkit` to store, retrieve, and query the dynamically invented predicates. This allows new concepts to become part of the shared, long-term knowledge base for all agents.
- [ ] **Task 4: Develop a `SymbolicOperatorLearner` Agent.**
    - This new agent will periodically query `KhalaMemory` for clusters of successful and failed trades related to a specific strategy.
    - It will use the paper's `associative model learning` approach to abstract these executions into a formal `StrategyOperator` with explicit preconditions and effects, using the expanded set of dynamic predicates. These operators can then be used by the `PlannerAgent` for more robust strategy selection and composition.
