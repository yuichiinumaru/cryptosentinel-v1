# Arxiv Analysis: LARCH: Large Language Model-based Automatic Readme Creation with Heuristics

**ID:** 2308.03099
**Date:** 2023-08-07
**Link:** https://arxiv.org/abs/2308.03099

## Executive Summary
The paper introduces LARCH, a system that leverages Large Language Models (LLMs) to automatically generate README files for software repositories. The core innovation is a heuristic-based method to identify "representative code fragments" from a large codebase. By feeding these smaller, more relevant fragments to the LLM, LARCH produces more coherent and factually correct documentation, outperforming baselines that use the entire codebase as context. This demonstrates the value of context distillation and filtering *before* engaging an LLM.

## Idea Brainstorming
*What concepts are potentially useful for THIS project?*
- **Heuristic-Based Context Filtering:** The central idea of identifying "representative" information is directly applicable to our `L2 (Perception) Triage Layer`. Instead of just routing based on simple intent, the Triage agent could use heuristics to extract the most salient parts of a user's request or incoming market data before passing it to the `L3 (Cognition)` layer. This creates a more focused, less noisy, and more efficient context for the specialist agents.
- **Dynamic Prompt Scaffolding:** LARCH's technique can be adapted for our `Dynamic Prompting` domain. The `PromptBuilder` could use a similar heuristic engine to select and combine the most relevant prompt templates or fragments based on the triage layer's analysis, rather than relying on a static mapping. This makes the system more adaptive to novel or complex queries.
- **"Weak Supervision" for Heuristic Refinement:** The paper mentions "weak supervision." We could adapt this for self-improvement. If a spawned agent's output is successful (e.g., a profitable trade), the initial context and the generated prompt could be saved as a positive example, providing a weak signal for refining the triage heuristics over time.

## Gap Analysis
*Compare paper concepts vs. `current_codebase`. What do we already have? What is missing?*

| Feature/Concept | Current State (Codebase) | Missing / Needed |
| :--- | :--- | :--- |
| Heuristic-Based Context Triage | The architecture in `docs/01-plan.md` defines a conceptual "Triage Layer," but it is not yet implemented. | A concrete implementation of a heuristic engine. We need to define what "representative" means in our domain (e.g., key market events, specific user intent keywords, portfolio state anomalies) and build a system to extract this information. |
| Dynamic Prompt Assembly | The `PromptBuilder` is planned (`docs/02-tasks.md`) but not implemented. The current design appears to rely on selecting whole templates, not composing them. | The `PromptBuilder` needs to be more sophisticated. It should be capable of *composing* a prompt from smaller, reusable fragments based on the rich, filtered context provided by the new Triage Layer. |
| Self-Improvement via Weak Supervision | No mechanism for agent self-improvement or feedback currently exists in the architecture. | A feedback loop. This would likely require a new component in the `backend/storage/` layer to log agent outcomes and a service to analyze these logs to update the triage heuristics. |

## Implementation Plan
*Granular, step-by-step task list to port the ideas to our code.*

- [ ] Task 1: **Define Triage Heuristics.** Research and define a set of heuristics for identifying "representative" information from user queries and market data streams (e.g., regex for intent, volatility thresholds, keyword extraction).
- [ ] Task 2: **Implement a `HeuristicTriageAgent`.** Create a new agent for the `L2` layer whose primary role is to filter and enrich context using the defined heuristics before passing it to the `AgentSpawner`.
- [ ] Task 3: **Enhance `PromptBuilder`.** Refactor the planned `PromptBuilder` to support the composition of prompts from multiple fragments, guided by the enriched context from the `HeuristicTriageAgent`.
- [ ] Task 4: **Design a Feedback Loop Mechanism.** Architect a system for logging agent outcomes and using that data to refine the triage heuristics, potentially via a simple scoring system based on task completion or trade outcomes.
