# Arxiv Analysis: OEMA: Ontology-Enhanced Multi-Agent Collaboration Framework for Zero-Shot Clinical Named Entity Recognition

**ID:** 2511.15211
**Date:** 2024-11-25
**Link:** https://arxiv.org/abs/2511.15211

## Executive Summary
The paper introduces OEMA, a multi-agent framework for zero-shot clinical Named Entity Recognition (NER). It uses a self-annotator to generate data, a discriminator guided by the SNOMED CT ontology to select high-quality examples, and a predictor to perform the final NER. The key innovation is using a medical ontology to improve example selection for few-shot learning in a zero-shot setting. This approach significantly improves performance over existing zero-shot methods and is comparable to supervised methods in some cases.

## Idea Brainstorming
*What concepts are potentially useful for THIS project?*
- **Ontology-Enhanced Example Selection:** The core idea of using an ontology to improve example selection is highly relevant. In our case, we could use a financial ontology (e.g., FIBO) to select relevant examples for tasks like identifying financial instruments, economic events, or market sentiment from news articles.
- **Multi-Agent Collaboration:** The paper's three-agent approach (Self-Annotator, Discriminator, Predictor) is a good model for our own multi-agent system. We already have a multi-agent architecture, but we could adopt this specific pattern for tasks that require a "generate-filter-predict" workflow.
- **Self-Annotation for Data Augmentation:** The self-annotator concept is a powerful way to augment our training data without manual labeling. We can use our existing agents to annotate unlabeled financial news or social media data, which can then be used to fine-tune our models.
- **Dual Prompting Strategy:** The use of both entity-type descriptions and structured examples in the prompt is a good practice to improve the performance of LLMs. We can apply this to our own prompting strategies.

## Gap Analysis
*Compare paper concepts vs. `current_codebase`. What do we already have? What is missing?*

| Feature/Concept | Current State (Codebase) | Missing / Needed |
| :--- | :--- | :--- |
| Multi-Agent Architecture | The project already has a multi-agent architecture with agents like `MarketAnalyst`, `Trader`, etc. | The specific "generate-filter-predict" pattern from the paper is not explicitly implemented. |
| Ontology Integration | No evidence of ontology integration in the current codebase. | We would need to integrate a financial ontology like FIBO and develop the logic to use it for example selection. |
| Self-Annotation | No self-annotation pipeline exists. | A new agent or a modification to an existing one would be needed to implement a self-annotation workflow. |
| Advanced Prompting | The project uses a `PromptBuilder` for dynamic prompt generation. | The dual prompting strategy of combining type priors and structured examples is not explicitly enforced. |

## Implementation Plan
*Granular, step-by-step task list to port the ideas to our code.*

- [ ] **Research Financial Ontologies:** Investigate and select a suitable financial ontology (e.g., FIBO, gist).
- [ ] **Develop an Ontology-Enhanced Discriminator Agent:** Create a new agent responsible for filtering and selecting examples based on the chosen ontology. This agent would be similar to the discriminator in the OEMA framework.
- [ ] **Implement a Self-Annotator Agent:** Create a new agent that can autonomously annotate unlabeled financial data. This would involve using one of our existing agents (like `MarketAnalyst`) to perform the initial annotation.
- [ ] **Integrate the New Agents into the existing workflow:** Modify the agent factory and orchestration logic to incorporate the new `SelfAnnotator` and `OntologyDiscriminator` agents.
- [ ] **Refine Prompting Strategies:** Update the `PromptBuilder` to incorporate the dual prompting strategy, combining entity-type descriptions with the ontology-selected examples.
