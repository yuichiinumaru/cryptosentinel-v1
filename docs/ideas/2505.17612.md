# Arxiv Analysis: Distilling LLM Agent into Small Models with Retrieval and Code Tools

**ID:** 2505.17612
**Date:** 2024-05-29
**Link:** https://arxiv.org/abs/2505.17612

## Executive Summary
The paper proposes **Agent Distillation**, a framework to transfer the complex, tool-using behaviors of large language models (LLMs) to smaller, more efficient models (sLMs). This goes beyond simple reasoning (CoT) distillation by teaching sLMs *how* to act and use tools (like code interpreters and retrieval systems) rather than just memorizing static reasoning paths. The key innovations are the **"First-Thought Prefix" (FTP)** to improve the quality of training data generated by the teacher LLM, and **"Self-Consistent Action Generation" (SAG)** to improve the robustness of the student sLM at inference time. The results show that sLMs as small as 0.5B parameters can achieve performance competitive with much larger models, making capable, tool-using agents more practical and accessible.

## Idea Brainstorming
This paper is highly relevant to the project's "ARTEMIS" architecture, which focuses on dynamic, ephemeral, and specialized agents.
- **Concept 1: First-Thought Prefix (FTP).** The FTP method aligns perfectly with the `PromptBuilder` concept outlined in `docs/01-plan.md`. We can enhance our `PromptBuilder` to generate a preliminary CoT-style prompt for our "teacher" model (e.g., a powerful Gemini or GPT model), extract the initial high-level reasoning step, and then use that step as a prefix to generate the full "agentic trajectory" (the think-act-observe cycle). This would generate higher-quality training data for distilling our own specialized, smaller "worker" agents.
- **Concept 2: Self-Consistent Action Generation (SAG).** The SAG method is a powerful technique for improving the reliability of tool-using agents, which is a known challenge. This could be implemented as a `ToolExecutionManager` or a "wrapper" around our toolkits. When a worker agent decides to use a tool, this manager would not execute it immediately. Instead, it would sample multiple thought-action sequences from the agent, execute them in parallel (or serially), filter out any that produce errors, and then use a majority vote on the results to select the most reliable action. This directly addresses the risk of smaller, distilled agents generating faulty code or making incorrect tool calls, as mentioned in the paper.

## Gap Analysis
*Compare paper concepts vs. `current_codebase`. What do we already have? What is missing?*

| Feature/Concept | Current State (Codebase) | Missing / Needed |
| :--- | :--- | :--- |
| **Agent Distillation** | The project uses a static factory (`get_crypto_trading_team`) to create a fixed set of agents. There is no existing mechanism for distilling behaviors from a "teacher" to a "student" model. | A full distillation pipeline, including trajectory generation, data formatting, and fine-tuning scripts. |
| **First-Thought Prefix** | The `PromptBuilder` concept exists in the ARTEMIS plan (`docs/01-plan.md`) but is not yet implemented. Current agents use static `instructions.md` files. | Implementation of the `PromptBuilder` with the specific logic to generate a CoT, extract the first thought, and then use it as a prefix for generating the final agentic prompt. |
| **Self-Consistent Action Generation** | Agents call tools directly (e.g., `dex_toolkit_instance.swap(...)`). There is no mechanism for sampling multiple actions or verifying consistency. | A `ToolExecutionManager` or "wrapper" that intercepts tool calls, manages the sampling of multiple action candidates, executes them, and performs the majority vote to select the final action. |
| **Tool-Using Agents** | The system has a robust framework for tool-using agents, with multiple toolkits (`DexToolkit`, `MarketDataToolkit`, etc.). | The current tools are used in a "greedy" fashion. The SAG concept would add a layer of robustness on top of this existing framework. |

## Implementation Plan
*Granular, step-by-step task list to port the ideas to our code.*

- [ ] Task (New): Enhance `PromptBuilder` with FTP Logic.
    -   As part of Task 1.2 (`Implement PromptBuilder interface`), add a method `build_trajectory_generation_prompt(context)` that implements the First-Thought Prefix logic.
    -   This will involve a two-step generation process: first, generate the CoT, then use the first step as a prefix for the agentic prompt.
- [ ] Task (New): Implement `ToolExecutionManager` with SAG Logic.
    -   Create a new module `backend/execution/manager.py`.
    -   Implement a `ToolExecutionManager` class that wraps toolkits.
    -   This class will have an `execute_tool` method that, when called, triggers the Self-Consistent Action Generation logic (sampling, execution, filtering, voting).
    -   This can be integrated with the `Refinement Loop Wrapper` from Task 4.3.2.
- [ ] Task (New): Create Agent Distillation Pipeline.
    -   Create a new script `scripts/distill_agent.py`.
    -   This script will use the FTP-enhanced `PromptBuilder` to generate a dataset of high-quality agentic trajectories from a teacher model.
    -   It will then use this dataset to fine-tune a smaller, specialized student model (e.g., a smaller version of Gemini or another open-source model).
    -   This aligns with the overall goal of creating "Ephemeral Workers" in the ARTEMIS architecture.
