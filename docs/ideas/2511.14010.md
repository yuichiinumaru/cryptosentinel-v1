# Arxiv Analysis: Knowledge-Grounded Agentic Large Language Models for Multi-Hazard Understanding from Reconnaissance Reports

**ID:** 2511.14010
**Date:** 2024-11-26
**Link:** https://arxiv.org/abs/2511.14010

## Executive Summary
The paper introduces the **Mixture-of-Retrieval Agentic RAG (MoRA-RAG)**, a framework designed to enhance the reliability of Large Language Models by improving how they retrieve and process information from external knowledge bases. Its core innovation is a dual-pronged approach: a **Mixture-of-Retrievers (MoR)** mechanism that intelligently routes queries to specialized databases, and an **Agentic Verification Loop** that uses a team of specialized AI agents to validate, supplement, and refine retrieved evidence *before* it's used for generating an answer. This system significantly improves factual accuracy, reduces hallucinations, and allows smaller, open-weight models to achieve performance comparable to large, proprietary ones.

## Idea Brainstorming
*What concepts are potentially useful for THIS project?*
- **Concept 1: Mixture-of-Retrievers (MoR):** Instead of a single, monolithic memory database (`khala_integration`), we could partition our agent memories into specialized, domain-specific databases (e.g., a `market_data_db`, a `security_analysis_db`, a `trading_strategy_db`). A new `RouterAgent` would first analyze an agent's query and direct it to the most relevant database, improving retrieval speed and relevance while reducing noise from irrelevant contexts.

- **Concept 2: Agentic Chunking:** The current `store_memory` function saves raw text. We can enhance this by creating a `MemoryIngestionAgent`. This agent would intercept content before it's saved, use an LLM to identify and extract key factual propositions, and then group and summarize them into a coherent, context-rich "chunk." This ensures that memories are stored in a structured, semantically complete format, making future retrievals far more effective.

- **Concept 3: Agentic Verification Loop:** Agents currently trust information from `search_memory` implicitly. We could implement a new `VerifierAgentTeam` that acts as an intermediary. When an agent queries memory, this team would intercept the results and perform a validation cycle:
    1.  An `EvidenceEvaluator` agent assesses if the retrieved memory is sufficient to answer the query.
    2.  If not, an `OnlineSearchAgent` uses existing web tools to find supplemental, real-time information.
    3.  If the combined evidence is still insufficient, a `QueryRewriterAgent` refines the original query and re-searches the memory system.
    4.  Only after this loop confirms the evidence is sufficient and reliable is it passed back to the original agent.

## Gap Analysis
*Compare paper concepts vs. `current_codebase`. What do we already have? What is missing?*

| Feature/Concept | Current State (Codebase) | Missing / Needed |
| :--- | :--- | :--- |
| **Mixture-of-Retrievers** | A monolithic memory system (`khala_integration.py`) where all agents query a single SurrealDB database using a generic BM25 search. | A `RouterAgent` to direct queries. The ability to create and manage multiple, domain-specific memory databases/tables within SurrealDB. |
| **Agentic Chunking** | Raw, unstructured text is stored directly via the `store_memory` function. There is no pre-processing to ensure contextual integrity. | A `MemoryIngestionAgent` or service layer to intercept, process, and structure text into summarized, proposition-based chunks before saving. |
| **Agentic Verification Loop** | Agents directly call `search_memory` and immediately use the returned text. There is no mechanism for validating sufficiency or accuracy. | A `VerifierAgentTeam` to intercept memory results and execute the "evaluate, search, rewrite" cycle. This represents a fundamental shift from a simple lookup to a validated retrieval pipeline. |

## Implementation Plan
*Granular, step-by-step task list to port the ideas to our code.*

- [ ] **Phase 1: Mixture-of-Retrievers**
    - [ ] Task 1: Design a schema to support multiple memory tables within SurrealDB (e.g., `memories_market`, `memories_security`, `memories_execution`).
    - [ ] Task 2: Implement a `RouterAgent` that takes a natural language query and outputs a target table name.
    - [ ] Task 3: Refactor `KhalaMemoryToolkit` to use the `RouterAgent` to dynamically select and query the appropriate memory table.
- [ ] **Phase 2: Agentic Chunking**
    - [ ] Task 4: Create a new `MemoryIngestionAgent` with instructions to decompose text into propositions and create a summarized, structured chunk.
    - [ ] Task 5: Modify the `store_memory` function in `KhalaMemoryToolkit` to invoke the `MemoryIngestionAgent` before writing to the database.
- [ ] **Phase 3: Agentic Verification Loop**
    - [ ] Task 6: Implement the `VerifierAgentTeam`, consisting of an `EvidenceEvaluator`, `OnlineSearchAgent` (re-using existing tools), and `QueryRewriterAgent`.
    - [ ] Task 7: Create a new service, `VerifiedMemorySearch`, that wraps the `search_memory` function and executes the verification loop.
    - [ ] Task 8: Update all agents that currently use `KhalaMemoryToolkit.search_memory` to use the new `VerifiedMemorySearch` service instead.
